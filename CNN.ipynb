{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data  #  批训练所需\n",
    "import torchvision  # 手写数据库模块\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH=1  # 训练次数\n",
    "BATCH_SIZE=50  # 每批训练的个数\n",
    "LR=0.001  # 学习速率\n",
    "DOWNLOAD_MNIST=False  # 是否下载MNIST数据\n",
    "# 得到MNIST数据\n",
    "train_data=torchvision.datasets.MNIST(\n",
    "    root='./mnist',  # 下载到的文件夹\n",
    "    train=True,  # 获取的是否是训练集数据,若为False则是获取测试集数据\n",
    "    transform=torchvision.transforms.ToTensor(),  # 将下载的数据集转换为Tensor,其维度是[C,H,W]\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "# 获取测试用的MNIST数据\n",
    "test_data=torchvision.datasets.MNIST(root='./mnist/',train=False)\n",
    "\n",
    "test_x=Variable(torch.unsqueeze(test_data.test_data,dim=1),volatile=True).type(torch.FloatTensor)[:2000]/255\n",
    "test_y=test_data.test_labels[:2000]\n",
    "# plot the MNIST\n",
    "# print(train_data.train_data.size())\n",
    "# print(train_data.train_labels.size())\n",
    "# print(train_data.train_data[0])\n",
    "plt.imshow(train_data.train_data[0].numpy(),cmap='gray')\n",
    "plt.title('%i'%train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchvision.datasets.mnist.MNIST object at 0x7f8fa0974ba8>\n",
      "<class 'torch.ByteTensor'>\n",
      "torch.Size([60000, 28, 28])\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0    80\n",
      "    0     0     0     0     0     0     0     0     0     0     0    32   253\n",
      "    0     0     0     0     0     0     0     0     0     0     0   151   251\n",
      "    0     0     0     0     0     0     0     0     0     0    48   221   251\n",
      "    0     0     0     0     0     0     0     0     0     0   234   251   251\n",
      "    0     0     0     0     0     0     0     0     0     0   253   251   251\n",
      "    0     0     0     0     0     0     0     0     0   159   255   253   253\n",
      "    0     0     0     0     0     0     0     0    48   228   253   247   140\n",
      "    0     0     0     0     0     0     0     0    64   251   253   220     0\n",
      "    0     0     0     0     0     0     0     0    64   251   253   220     0\n",
      "    0     0     0     0     0     0     0     0    24   193   253   220     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0   124   253   255    63     0     0     0     0\n",
      "    0     0     0     0    96   244   251   253    62     0     0     0     0\n",
      "    0     0     0     0   127   251   251   253    62     0     0     0     0\n",
      "    0     0     0    68   236   251   211    31     8     0     0     0     0\n",
      "    0     0    60   228   251   251    94     0     0     0     0     0     0\n",
      "    0     0   155   253   253   189     0     0     0     0     0     0     0\n",
      "    0    20   253   251   235    66     0     0     0     0     0     0     0\n",
      "   32   205   253   251   126     0     0     0     0     0     0     0     0\n",
      "  104   251   253   184    15     0     0     0     0     0     0     0     0\n",
      "  240   251   193    23     0     0     0     0     0     0     0     0     0\n",
      "  253   253   159     0     0     0     0     0     0     0     0     0     0\n",
      "  251   251    39     0     0     0     0     0     0     0     0     0     0\n",
      "  251   172     0     0     0     0     0     0     0     0     0     0     0\n",
      "  196    12     0     0     0     0     0     0     0     0     0     0     0\n",
      "   89     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   31     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    8     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 27 \n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.ByteTensor of size 28x28]\n",
      "\n",
      "<torchvision.datasets.mnist.MNIST object at 0x7f9005465a58>\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(type(train_data.train_data))\n",
    "print(train_data.train_data.shape)  # 该数据集共60000张图片\n",
    "print(train_data.train_data[3])  # 每一张图像的数据是一个28*28的ByteTensor\n",
    "print(test_data)\n",
    "print(test_data.test_data.shape)  # 测试集有10000张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=Data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1=nn.Sequential(  # input shape (1,28,28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,  # 卷积核的大小5*5\n",
    "                stride=1,  # 卷积的步长\n",
    "                padding=2,  # 图像四周的填充\n",
    "            ),  # output shape(16,28,28) 卷积层将高度为1的图像卷积成了高度16的图像\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.MaxPool2d(kernel_size=2),  # 池化层,最大法,其池化的核大小为2*2\n",
    "        )  # output变为一16,14,14\n",
    "        self.conv2=nn.Sequential(  # input shape (16,14,14)\n",
    "            nn.Conv2d(16,32,5,1,2),  # 卷积层的参数的简化写法 output(32,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # --->(32,7,7)\n",
    "        )\n",
    "        self.out=nn.Linear(32*7*7,10)  # 全连接层,进行线性分类\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=x.view(x.size(0),-1)  #  展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n",
    "        output=self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d (1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d (16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (out): Linear(in_features=1568, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(cnn.parameters(),lr=LR)\n",
    "loss_func=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 |train loss:2.2999 |test accuracy: 0.15\n",
      "Epoch 0 |train loss:0.3402 |test accuracy: 0.8255\n",
      "Epoch 0 |train loss:0.3186 |test accuracy: 0.897\n",
      "Epoch 0 |train loss:0.1971 |test accuracy: 0.9235\n",
      "Epoch 0 |train loss:0.1576 |test accuracy: 0.945\n",
      "Epoch 0 |train loss:0.0851 |test accuracy: 0.934\n",
      "Epoch 0 |train loss:0.1416 |test accuracy: 0.959\n",
      "Epoch 0 |train loss:0.0266 |test accuracy: 0.952\n",
      "Epoch 0 |train loss:0.2082 |test accuracy: 0.9595\n",
      "Epoch 0 |train loss:0.0884 |test accuracy: 0.963\n",
      "Epoch 0 |train loss:0.1433 |test accuracy: 0.9655\n",
      "Epoch 0 |train loss:0.1759 |test accuracy: 0.9665\n",
      "Epoch 0 |train loss:0.0510 |test accuracy: 0.9705\n",
      "Epoch 0 |train loss:0.1347 |test accuracy: 0.9685\n",
      "Epoch 0 |train loss:0.0234 |test accuracy: 0.9705\n",
      "Epoch 0 |train loss:0.0492 |test accuracy: 0.9675\n",
      "Epoch 0 |train loss:0.0443 |test accuracy: 0.969\n",
      "Epoch 0 |train loss:0.0629 |test accuracy: 0.9725\n",
      "Epoch 0 |train loss:0.0055 |test accuracy: 0.977\n",
      "Epoch 0 |train loss:0.0231 |test accuracy: 0.978\n",
      "Epoch 0 |train loss:0.0581 |test accuracy: 0.9785\n",
      "Epoch 0 |train loss:0.0171 |test accuracy: 0.9805\n",
      "Epoch 0 |train loss:0.1121 |test accuracy: 0.9755\n",
      "Epoch 0 |train loss:0.0623 |test accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        b_x=Variable(x)\n",
    "        b_y=Variable(y)\n",
    "        \n",
    "#         print(step)\n",
    "        \n",
    "        output=cnn(b_x)\n",
    "        loss=loss_func(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if step%50==0:\n",
    "            test_output=cnn(test_x)\n",
    "            # 得到预测的结果\n",
    "            pred_y=torch.max(test_output,1)[1].data.squeeze()  # max方法得到在dim=1上输入的Tensor的最大值\n",
    "            accuracy=sum(pred_y==test_y)/test_y.size(0)  # sum()这里应该是算出测试结果与答案相等的数量\n",
    "            print('Epoch',epoch,'|train loss:%.4f'%loss.data[0],'|test accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 3 9 5] prediction number\n",
      "[7 2 1 ... 3 9 5] real number\n"
     ]
    }
   ],
   "source": [
    "# 利用测试集进行测试\n",
    "test_output=cnn(test_x)\n",
    "pred_y=torch.max(test_output,1)[1].data.numpy().squeeze()\n",
    "print(pred_y,'prediction number')\n",
    "print(test_y.numpy(),'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
